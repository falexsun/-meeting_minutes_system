# Использование LM Studio для генерации протоколов

## Что такое LM Studio?

LM Studio - это локальное приложение для запуска больших языковых моделей (LLM) на вашем компьютере. Оно предоставляет OpenAI-совместимый API, что делает его отличной альтернативой Ollama.

## Установка LM Studio

1. Скачайте LM Studio с официального сайта: https://lmstudio.ai/
2. Установите приложение
3. Запустите LM Studio

## Загрузка модели

1. В LM Studio откройте вкладку **Search** (Поиск)
2. Найдите и загрузите одну из рекомендуемых моделей:
   - **vikhr-nemo-12b-instruct-r-21-09-24** (отлично для русского языка, 12B параметров)
   - **Qwen/Qwen2.5-7B-Instruct-GGUF** (отличный выбор для русского языка)
   - **bartowski/Llama-3.1-8B-Instruct-GGUF**
   - **TheBloke/Mistral-7B-Instruct-v0.2-GGUF**

3. Выберите квантизацию (рекомендуется Q4_K_M или Q5_K_M для баланса скорости и качества)

## Запуск локального сервера

1. В LM Studio перейдите в **Local Server** (Локальный сервер)
2. Выберите загруженную модель
3. Настройте параметры:
   - **Context Length**: 4096 или больше
   - **GPU Offload**: максимум (если есть GPU)
4. Нажмите **Start Server** (Запустить сервер)
5. Сервер запустится на `http://localhost:1234`

## Настройка Meminto

1. Скопируйте `.env.example` в `.env`:
   ```powershell
   Copy-Item .env.example .env
   ```

2. Отредактируйте `.env` файл:
   ```env
   HUGGING_FACE_ACCESS_TOKEN=ваш_токен_здесь
   
   LMSTUDIO_MODEL=vikhr-nemo-12b-instruct-r-21-09-24
   LMSTUDIO_URL=http://localhost:1234/v1/chat/completions
   LMSTUDIO_MAX_TOKENS=8000
   ```

## Запуск программы

```powershell
# Активируйте виртуальное окружение
.\venv\Scripts\Activate.ps1

# Запустите с флагом --use-lmstudio
python meminto/main.py -f examples/your_audio.wav -l russian --use-lmstudio
```

## Преимущества LM Studio перед Ollama

✅ **Удобный интерфейс** - графический интерфейс для управления моделями  
✅ **OpenAI API** - стандартный формат запросов  
✅ **Простая настройка** - не требует знания терминала  
✅ **Мониторинг** - видно использование ресурсов в реальном времени  
✅ **Квантизация** - оптимизация для вашего железа  

## Рекомендуемые настройки для протоколов

- **Temperature**: 0.3-0.5 (для более точных результатов)
- **Max Tokens**: 8000 (для длинных совещаний)
- **Context Length**: минимум 4096

## Проблемы и решения

### Ошибка 502 Bad Gateway
- Убедитесь, что сервер LM Studio запущен
- Проверьте, что модель загружена
- Перезапустите LM Studio

### Медленная генерация
- Уменьшите квантизацию (Q4 вместо Q8)
- Увеличьте GPU Offload
- Используйте модель меньшего размера

### Ошибки памяти
- Закройте другие приложения
- Используйте модель с меньшей квантизацией
- Уменьшите Context Length

## Сравнение с Ollama

| Характеристика | LM Studio | Ollama |
|---------------|-----------|--------|
| Интерфейс | GUI + API | Только CLI |
| Установка | Простая | Требует терминала |
| API формат | OpenAI | Собственный |
| Управление моделями | Графическое | Командная строка |
| Мониторинг | Встроенный | Отсутствует |

## Дополнительная информация

- Документация LM Studio: https://lmstudio.ai/docs
- Каталог моделей: https://huggingface.co/models?library=gguf
- Сообщество: https://discord.gg/lmstudio
