# =============================================================================
# Конфигурация Meminto - ТОЛЬКО ЛОКАЛЬНЫЕ МОДЕЛИ
# ВСЕ ДАННЫЕ ОБРАБАТЫВАЮТСЯ ЛОКАЛЬНО, БЕЗ ПЕРЕДАЧИ НА ВНЕШНИЕ СЕРВИСЫ
# =============================================================================

# -----------------------------------------------------------------------------
# Hugging Face Access Token (обязательно)
# Необходим ТОЛЬКО для загрузки моделей диаризации (разделения по спикерам)
# Модели загружаются ОДИН РАЗ и затем работают локально
# Как получить токен:
# 1. Зарегистрируйтесь на https://huggingface.co/
# 2. Перейдите на https://huggingface.co/pyannote/speaker-diarization
# 3. Примите условия использования
# 4. Получите токен на https://huggingface.co/settings/tokens
# ВАЖНО: Токен используется только для загрузки моделей, данные не передаются!
# -----------------------------------------------------------------------------
HUGGING_FACE_ACCESS_TOKEN=your_hugging_face_token_here

# -----------------------------------------------------------------------------
# Настройки LM Studio (для локальной LLM) - ПО УМОЛЧАНИЮ
# Все данные обрабатываются на вашем компьютере
# -----------------------------------------------------------------------------
# Модель LM Studio для генерации протоколов
# Рекомендуемые модели для русского языка:
# - vikhr-nemo-12b-instruct-r-21-09-24 (отлично для русского языка, 12B параметров)
# - Qwen/Qwen2.5-7B-Instruct (отличная поддержка русского языка)
# - Llama-3.1-8B-Instruct (хорошая производительность)
# - mistralai/Mistral-7B-Instruct-v0.2 (универсальная модель)
LMSTUDIO_MODEL=vikhr-nemo-12b-instruct-r-21-09-24

# URL LM Studio API (ЛОКАЛЬНЫЙ сервер, стандартный порт 1234)
LMSTUDIO_URL=http://localhost:1234/v1/chat/completions

# Максимальное количество токенов для генерации
# Для совещаний длительностью 1-2 часа рекомендуется 8000
LMSTUDIO_MAX_TOKENS=8000

# -----------------------------------------------------------------------------
# Настройки Ollama (альтернатива LM Studio)
# Все данные также обрабатываются локально
# -----------------------------------------------------------------------------
# Модель Ollama для генерации протоколов
# Рекомендуемые модели для русского языка:
# - qwen2.5:7b (отличная поддержка русского языка)
# - llama3.2 (быстрая, хорошо работает с русским)
# - mistral (хорошая альтернатива)
OLLAMA_MODEL=qwen2.5:7b

# URL Ollama API (ЛОКАЛЬНЫЙ сервер)
OLLAMA_URL=http://localhost:11434/api/generate

# Максимальное количество токенов для генерации
OLLAMA_MAX_TOKENS=8000

# =============================================================================
# ГАРАНТИЯ КОНФИДЕНЦИАЛЬНОСТИ:
# - Все аудио обрабатывается локально (Whisper)
# - Диаризация выполняется локально (pyannote.audio)
# - Генерация протокола выполняется локально (LM Studio или Ollama)
# - НИКАКИЕ данные не передаются на сторонние серверы
# - Hugging Face токен используется ТОЛЬКО для загрузки моделей
# =============================================================================

# -----------------------------------------------------------------------------
# Настройки удаленного транскрайбера (опционально)
# Используйте, если хотите использовать удаленный сервер для транскрипции
# вместо локального Whisper
# -----------------------------------------------------------------------------
# TRANSCRIBER_URL=http://your-transcriber-server/v1/audio/transcriptions
# TRANSCRIBER_AUTHORIZATION=Bearer your_api_key_here

# -----------------------------------------------------------------------------
# Настройки для использования внешних LLM API (альтернатива Ollama)
# Используйте эти настройки, если НЕ используете флаг --use-ollama
# -----------------------------------------------------------------------------
# Для OpenAI:
# LLM_URL=https://api.openai.com/v1/chat/completions
# LLM_MODEL=gpt-4
# LLM_MAX_TOKENS=4000
# LLM_AUTHORIZATION=Bearer your_openai_api_key

# Для Azure OpenAI:
# LLM_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions?api-version=2023-05-15
# LLM_MODEL=gpt-4
# LLM_MAX_TOKENS=4000
# LLM_AUTHORIZATION=your_azure_api_key

# Для локального сервера OpenAI-совместимого API:
# LLM_URL=http://localhost:8000/v1/chat/completions
# LLM_MODEL=your_model_name
# LLM_MAX_TOKENS=4000
# LLM_AUTHORIZATION=Bearer your_api_key
